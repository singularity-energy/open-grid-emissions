{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "\n",
    "# # Tell python where to look for modules.\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src/\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import oge.load_data as load_data\n",
    "from oge.filepaths import *\n",
    "import oge.data_cleaning as data_cleaning\n",
    "from oge.logging_util import get_logger, configure_root_logger\n",
    "from oge.validation import check_for_orphaned_cc_part_in_subplant\n",
    "\n",
    "configure_root_logger()\n",
    "logger = get_logger(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Need to introduce the concept of a static earliest year\n",
    "\n",
    "# The earliest_year represents the earliest year that the OGE dataset will ever cover\n",
    "# data back to 2001 is available in PUDL, but EIA-860 files prior to 2004 was distributed\n",
    "# in a different format that may not be consistent with later files, and may use\n",
    "# different primary keys for generators.\n",
    "# https://catalystcoop-pudl.readthedocs.io/en/v2023.12.01/data_sources/eia860.html#how-much-of-the-data-is-accessible-through-pudl\n",
    "earliest_year = 2005\n",
    "year = 2022\n",
    "\n",
    "path_prefix = f\"{year}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# although we could directly load all years at once from the cems parquet file, this\n",
    "# would lead to a memoryerror, so we load one year at a time and drop duplicates before\n",
    "# concatting the next year to the dataframe\n",
    "cems_ids = []\n",
    "# use 2001 as the start year as this is the earliest year that EIA data is available\n",
    "# in PUDL, and we would likely never use data before this year.\n",
    "for year in range(earliest_year, year + 1):\n",
    "    cems_id_year = pd.read_parquet(\n",
    "        downloads_folder(\"pudl/hourly_emissions_epacems.parquet\"),\n",
    "        filters=[[\"year\", \"==\", year]],\n",
    "        columns=[\"plant_id_epa\", \"plant_id_eia\", \"emissions_unit_id_epa\"],\n",
    "    ).drop_duplicates()\n",
    "    cems_ids.append(cems_id_year)\n",
    "    cems_ids = [pd.concat(cems_ids, axis=0).drop_duplicates()]\n",
    "cems_ids = (\n",
    "    pd.concat(cems_ids, axis=0)\n",
    "    .drop_duplicates()\n",
    "    .sort_values(by=[\"plant_id_eia\", \"emissions_unit_id_epa\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# generate_subplant_ids()\n",
    "\n",
    "import pudl.analysis.epacamd_eia as epacamd_eia\n",
    "\n",
    "# load the crosswalk and filter it by the data that actually exists in cems\n",
    "crosswalk = load_data.load_epa_eia_crosswalk(year)\n",
    "\n",
    "# filter the crosswalk to drop any units that don't exist in CEMS\n",
    "filtered_crosswalk = epacamd_eia.filter_crosswalk(crosswalk, cems_ids)\n",
    "\n",
    "######################################################\n",
    "from pudl.etl.glue_assets import make_subplant_ids\n",
    "\n",
    "# use graph analysis to identify subplants\n",
    "crosswalk_with_subplant_ids = make_subplant_ids(filtered_crosswalk)\n",
    "\n",
    "# change the eia plant id to int\n",
    "crosswalk_with_subplant_ids[\"plant_id_eia\"] = crosswalk_with_subplant_ids[\n",
    "    \"plant_id_eia\"\n",
    "].astype(int)\n",
    "\n",
    "# change the order of the columns\n",
    "crosswalk_with_subplant_ids = crosswalk_with_subplant_ids[\n",
    "    [\n",
    "        \"plant_id_epa\",\n",
    "        \"emissions_unit_id_epa\",\n",
    "        \"plant_id_eia\",\n",
    "        \"generator_id\",\n",
    "        \"subplant_id\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_complete_eia_generators_for_subplants(earliest_year, year):\n",
    "    complete_gens = load_data.load_pudl_table(\n",
    "        \"denorm_generators_eia\",\n",
    "        columns=[\n",
    "            \"report_date\",\n",
    "            \"plant_id_eia\",\n",
    "            \"generator_id\",\n",
    "            \"unit_id_pudl\",\n",
    "            \"prime_mover_code\",\n",
    "            \"operational_status_code\",\n",
    "            \"generator_operating_date\",\n",
    "            \"generator_retirement_date\",\n",
    "            \"original_planned_generator_operating_date\",\n",
    "            \"current_planned_generator_operating_date\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # create a column that indicates the earliest year a generator reported data to EIA\n",
    "    complete_gens[\"earliest_report_date\"] = complete_gens.groupby(\n",
    "        [\"plant_id_eia\", \"generator_id\"]\n",
    "    )[\"report_date\"].transform(\"min\")\n",
    "\n",
    "    # drop any data that was reported prior to the earliest year\n",
    "    # only keep data for years <= the year\n",
    "    # this avoids using potentially preliminary early-release data\n",
    "    complete_gens = complete_gens[\n",
    "        (complete_gens[\"report_date\"].dt.year >= earliest_year)\n",
    "        & (complete_gens[\"report_date\"].dt.year <= year)\n",
    "    ]\n",
    "\n",
    "    # for any retired gens, forward fill the most recently available unit_id_pudl to the\n",
    "    # most recent available year\n",
    "    complete_gens[\"unit_id_pudl\"] = complete_gens.groupby(\n",
    "        [\"plant_id_eia\", \"generator_id\"]\n",
    "    )[\"unit_id_pudl\"].ffill()\n",
    "\n",
    "    # only keep the most recent entry for each generator\n",
    "    complete_gens = complete_gens.sort_values(\n",
    "        by=[\"plant_id_eia\", \"generator_id\", \"report_date\"], ascending=True\n",
    "    ).drop_duplicates(subset=[\"plant_id_eia\", \"generator_id\"], keep=\"last\")\n",
    "\n",
    "    # remove generators that are proposed but not yet under construction, or cancelled\n",
    "    status_codes_to_remove = [\"CN\", \"IP\", \"P\", \"L\", \"T\"]\n",
    "    complete_gens = complete_gens[\n",
    "        ~complete_gens[\"operational_status_code\"].isin(status_codes_to_remove)\n",
    "    ]\n",
    "\n",
    "    # remove generators that retired prior to the earliest year\n",
    "    complete_gens = complete_gens[\n",
    "        ~(\n",
    "            (complete_gens[\"operational_status_code\"] == \"RE\")\n",
    "            & (complete_gens[\"generator_retirement_date\"].dt.year < earliest_year)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # remove generators that have no operating or retirement date, and the last time they\n",
    "    # reported data was prior to the current year. This is often proposed plants that are\n",
    "    # assigned a new plant_id_eia once operational\n",
    "    complete_gens = complete_gens[\n",
    "        ~(\n",
    "            (complete_gens[\"generator_operating_date\"].isna())\n",
    "            & (complete_gens[\"generator_retirement_date\"].isna())\n",
    "            & (complete_gens[\"report_date\"].dt.year < year)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    ####################\n",
    "    # merge into complete_gens and fill missing operating dates with the EIA-860 data\n",
    "    generator_data_from_eia860 = load_raw_eia860_generator_dates_and_unit_ids(year)\n",
    "    complete_gens = complete_gens.merge(\n",
    "        generator_data_from_eia860,\n",
    "        how=\"left\",\n",
    "        on=[\"plant_id_eia\", \"generator_id\"],\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "    complete_gens[\"generator_operating_date\"] = complete_gens[\n",
    "        \"generator_operating_date\"\n",
    "    ].fillna(complete_gens[\"operating_date_eia\"])\n",
    "    complete_gens = complete_gens.drop(columns=\"operating_date_eia\")\n",
    "\n",
    "    #######################\n",
    "    # update the unit_id_eia_numeric to be one higher than the highest existing unit_id_pudl\n",
    "    # if unit_id_eia_numeric is NA, the updated value should also still be na\n",
    "    complete_gens[\"unit_id_eia_numeric\"] = complete_gens[\n",
    "        \"unit_id_eia_numeric\"\n",
    "    ] + complete_gens.groupby(\"plant_id_eia\")[\"unit_id_pudl\"].transform(\"max\").fillna(0)\n",
    "\n",
    "    # fill in missing unit_id_pudl with the updated values\n",
    "    complete_gens[\"unit_id_pudl\"] = complete_gens[\"unit_id_pudl\"].fillna(\n",
    "        complete_gens[\"unit_id_eia_numeric\"]\n",
    "    )\n",
    "\n",
    "    return complete_gens\n",
    "\n",
    "\n",
    "def load_raw_eia860_generator_dates_and_unit_ids(year):\n",
    "    \"\"\"\n",
    "    Loads generator operating dates and unit_id_eia codes from the raw EIA-860 to\n",
    "    fill in missing dates and unit ids in the pudl data. PUDL deletes data for these\n",
    "    fields if there are inconsistencies across the historical data\n",
    "    \"\"\"\n",
    "    # load operating dates from the raw EIA-860 file to supplement missing operating dates\n",
    "    # from pudl\n",
    "    generator_op_dates_eia860 = pd.read_excel(\n",
    "        downloads_folder(f\"eia860/eia860{year}/3_1_Generator_Y{year}.xlsx\"),\n",
    "        header=1,\n",
    "        sheet_name=\"Operable\",\n",
    "        usecols=[\n",
    "            \"Plant Code\",\n",
    "            \"Generator ID\",\n",
    "            \"Operating Month\",\n",
    "            \"Operating Year\",\n",
    "            \"Unit Code\",\n",
    "        ],\n",
    "    ).rename(\n",
    "        columns={\n",
    "            \"Plant Code\": \"plant_id_eia\",\n",
    "            \"Generator ID\": \"generator_id\",\n",
    "            \"Operating Month\": \"Month\",\n",
    "            \"Operating Year\": \"Year\",\n",
    "            \"Unit Code\": \"unit_id_eia\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create a datetime column from the month and year\n",
    "    generator_op_dates_eia860[\"operating_date_eia\"] = pd.to_datetime(\n",
    "        generator_op_dates_eia860[[\"Year\", \"Month\"]].assign(Day=1)\n",
    "    )\n",
    "    generator_op_dates_eia860 = generator_op_dates_eia860.drop(\n",
    "        columns=[\"Month\", \"Year\"]\n",
    "    )\n",
    "\n",
    "    # load unit codes for proposed generators\n",
    "    proposed_unit_ids_eia860 = (\n",
    "        pd.read_excel(\n",
    "            downloads_folder(f\"eia860/eia860{year}/3_1_Generator_Y{year}.xlsx\"),\n",
    "            sheet_name=\"Proposed\",\n",
    "            header=1,\n",
    "            usecols=[\"Plant Code\", \"Generator ID\", \"Unit Code\"],\n",
    "        )\n",
    "        .dropna(subset=\"Unit Code\")\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"Plant Code\": \"plant_id_eia\",\n",
    "                \"Generator ID\": \"generator_id\",\n",
    "                \"Unit Code\": \"unit_id_eia\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # concat the data together\n",
    "    generator_data_from_eia860 = pd.concat(\n",
    "        [generator_op_dates_eia860, proposed_unit_ids_eia860], axis=0\n",
    "    )\n",
    "\n",
    "    # create a numeric version of the ID, starting at 1\n",
    "    generator_data_from_eia860[\"unit_id_eia_numeric\"] = (\n",
    "        generator_data_from_eia860.groupby(\n",
    "            [\"plant_id_eia\"]\n",
    "        )[\"unit_id_eia\"].transform(lambda x: pd.factorize(x)[0] + 1)\n",
    "    )\n",
    "\n",
    "    # unit_id_numeric of 0 represents missing unit_id_eia, so we want to replace these\n",
    "    # with nan\n",
    "    generator_data_from_eia860[\"unit_id_eia_numeric\"] = generator_data_from_eia860[\n",
    "        \"unit_id_eia_numeric\"\n",
    "    ].replace(0, np.NaN)\n",
    "\n",
    "    return generator_data_from_eia860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_gens = load_complete_eia_generators_for_subplants(earliest_year, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# update the subplant_crosswalk to ensure completeness\n",
    "# prepare the subplant crosswalk by adding a complete list of generators and adding\n",
    "# the unit_id_pudl column\n",
    "# complete_generator_ids = complete_gens[[\"plant_id_eia\", \"generator_id\", \"unit_id_pudl\"]].drop_duplicates()\n",
    "\n",
    "subplant_crosswalk_complete = crosswalk_with_subplant_ids.merge(\n",
    "    complete_gens,\n",
    "    how=\"outer\",\n",
    "    on=[\"plant_id_eia\", \"generator_id\"],\n",
    "    validate=\"m:1\",\n",
    ")\n",
    "# also add a complete list of cems emissions_unit_id_epa\n",
    "subplant_crosswalk_complete = subplant_crosswalk_complete.merge(\n",
    "    cems_ids[[\"plant_id_eia\", \"emissions_unit_id_epa\"]].drop_duplicates(),\n",
    "    how=\"outer\",\n",
    "    on=[\"plant_id_eia\", \"emissions_unit_id_epa\"],\n",
    "    validate=\"m:1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records with a missing generator_id\n",
    "# these records either do not exist in EIA, or they are not yet linked\n",
    "# NOTE: This may trigger new validation warnings with test_for_missing_subplant_id(),\n",
    "# but this is good because we want to flag where there is CEMS data that is not linked\n",
    "# to an EIA record\n",
    "subplant_crosswalk_complete = subplant_crosswalk_complete.dropna(subset=\"generator_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: plant_parts_eia does not contain all of the unit_id_pudl\n",
    "# we need to investigate another source (plant 613)\n",
    "\n",
    "# instead we will use denorm_generators_eia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For any generators that are proposed but not existing, we should always sort these last in case they are\n",
    "# never completed so that they do not mess up the order\n",
    "# eg plant 64811 UPT7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplant_crosswalk_complete[\"sort_date\"] = (\n",
    "    subplant_crosswalk_complete[\"generator_operating_date\"]\n",
    "    .fillna(subplant_crosswalk_complete[\"generator_retirement_date\"])\n",
    "    .fillna(subplant_crosswalk_complete[\"original_planned_generator_operating_date\"])\n",
    ")\n",
    "\n",
    "# sort values to ensure static order\n",
    "# for any generators built on the same date, sort by generator ID\n",
    "\n",
    "subplant_crosswalk = subplant_crosswalk_complete.sort_values(\n",
    "    by=[\n",
    "        \"plant_id_eia\",\n",
    "        \"earliest_report_date\",\n",
    "        \"sort_date\",\n",
    "        \"generator_id\",\n",
    "        \"emissions_unit_id_epa\",\n",
    "    ],\n",
    "    ascending=True,\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: connect_ids() seems to be incorrectly grouping ids\n",
    "# NOTE: subset should probably be [plant_id_iea, id_to_update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_ids(df, id_to_update, connecting_id):\n",
    "    \"\"\"Corrects an id value if it is connected by an id value in another column.\n",
    "\n",
    "    if multiple subplant_id are connected by a single unit_id_pudl, this groups these\n",
    "    subplant_id together\n",
    "    if multiple unit_id_pudl are connected by a single subplant_id, this groups these\n",
    "    unit_id_pudl together\n",
    "\n",
    "    Args:\n",
    "        df: dataframe containing columns with id_to_update and connecting_id columns\n",
    "        subplant_unit_pairs\n",
    "    \"\"\"\n",
    "\n",
    "    # get a table with all unique subplant to unit pairs\n",
    "    subplant_unit_pairs = df[\n",
    "        [\"plant_id_eia\", id_to_update, connecting_id]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    # identify if any non-NA id_to_update are duplicated, indicated that it is\n",
    "    # associated with multiple connecting_id\n",
    "    duplicates = subplant_unit_pairs[\n",
    "        (\n",
    "            subplant_unit_pairs.duplicated(\n",
    "                subset=[\"plant_id_eia\", connecting_id], keep=False\n",
    "            )\n",
    "        )\n",
    "        & (~subplant_unit_pairs[connecting_id].isna())\n",
    "    ].copy()\n",
    "\n",
    "    # if there are any duplicate units, indicating an incorrect id_to_update,\n",
    "    # fix the id_to_update\n",
    "    df[f\"{id_to_update}_connected_by_{connecting_id}\"] = df[id_to_update]\n",
    "    if len(duplicates) > 0:\n",
    "        # find the lowest number subplant id associated with each duplicated\n",
    "        # unit_id_pudl\n",
    "        duplicates.loc[:, f\"{id_to_update}_to_replace\"] = (\n",
    "            duplicates.groupby([\"plant_id_eia\", connecting_id])[id_to_update]\n",
    "            .min()\n",
    "            .iloc[0]\n",
    "        )\n",
    "        # merge this replacement subplant_id into the dataframe and use it to update\n",
    "        # the existing subplant id\n",
    "        df = df.merge(\n",
    "            duplicates,\n",
    "            how=\"left\",\n",
    "            on=[\"plant_id_eia\", id_to_update, connecting_id],\n",
    "            validate=\"m:1\",\n",
    "        )\n",
    "        df.update(\n",
    "            {\n",
    "                f\"{id_to_update}_connected_by_{connecting_id}\": df[\n",
    "                    f\"{id_to_update}_to_replace\"\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        df = df.drop(columns=f\"{id_to_update}_to_replace\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# update_subplant_ids()\n",
    "\n",
    "# update unit_id_pudl using the unit_id_eia loaded from EIA-860\n",
    "subplant_crosswalk = connect_ids(\n",
    "    subplant_crosswalk, id_to_update=\"unit_id_pudl\", connecting_id=\"unit_id_eia_numeric\"\n",
    ")\n",
    "subplant_crosswalk[\"unit_id_pudl\"] = subplant_crosswalk[\n",
    "    \"unit_id_pudl_connected_by_unit_id_eia_numeric\"\n",
    "]\n",
    "\n",
    "\n",
    "# Step 1: Create corrected versions of subplant_id and unit_id_pudl\n",
    "# if multiple unit_id_pudl are connected by a single subplant_id,\n",
    "# unit_id_pudl_connected groups these unit_id_pudl together\n",
    "subplant_crosswalk = connect_ids(\n",
    "    subplant_crosswalk, id_to_update=\"unit_id_pudl\", connecting_id=\"subplant_id\"\n",
    ")\n",
    "\n",
    "# if multiple subplant_id are connected by a single unit_id_pudl, group these\n",
    "# subplant_id together\n",
    "subplant_crosswalk = connect_ids(\n",
    "    subplant_crosswalk, id_to_update=\"subplant_id\", connecting_id=\"unit_id_pudl\"\n",
    ")\n",
    "\n",
    "# Step 2: Fill missing subplant_id\n",
    "# We will use unit_id_pudl to fill missing subplant ids, so first we need to fill\n",
    "# any missing unit_id_pudl. We do this by assigning a new unit_id_pudl to each\n",
    "# generator that isn't already grouped into a unit\n",
    "\n",
    "# since generat\n",
    "# create a numeric version of each generator_id\n",
    "# ngroup() creates a unique number for each element in the group\n",
    "# each unit\n",
    "subplant_crosswalk[\"numeric_generator_id\"] = subplant_crosswalk.groupby(\n",
    "    [\"plant_id_eia\"], dropna=False, sort=False\n",
    ")[\"generator_id\"].transform(lambda x: pd.factorize(x, use_na_sentinel=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when filling in missing unit_id_pudl, we don't want these numeric_generator_id to\n",
    "# overlap existing unit_id to ensure this, we will add 1000 to each of these numeric\n",
    "# generator ids to ensure they are unique 1000 was chosen as an arbitrarily high\n",
    "# number, since the largest unit_id_pudl is ~ 10.\n",
    "subplant_crosswalk[\"subplant_id_filled\"] = (\n",
    "    subplant_crosswalk[\"subplant_id_connected_by_unit_id_pudl\"]\n",
    "    .fillna(subplant_crosswalk[\"unit_id_pudl_connected_by_subplant_id\"] + 1000)\n",
    "    .fillna(subplant_crosswalk[\"numeric_generator_id\"] + 1000000)\n",
    ")\n",
    "\n",
    "# create a new unique subplant_id based on the connected subplant ids and the\n",
    "# filled unit_id\n",
    "subplant_crosswalk[\"new_subplant\"] = subplant_crosswalk.groupby(\n",
    "    [\"plant_id_eia\"], dropna=False, sort=False\n",
    ")[\"subplant_id_filled\"].transform(lambda x: pd.factorize(x, use_na_sentinel=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplant_crosswalk[subplant_crosswalk[\"plant_id_eia\"] == 58987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplant_crosswalk_final = subplant_crosswalk.copy()\n",
    "subplant_crosswalk_final[\"subplant_id\"] = subplant_crosswalk_final[\"new_subplant\"] + 1\n",
    "subplant_crosswalk_final = subplant_crosswalk_final.reset_index(drop=True)[\n",
    "    [\n",
    "        \"plant_id_epa\",\n",
    "        \"emissions_unit_id_epa\",\n",
    "        \"plant_id_eia\",\n",
    "        \"generator_id\",\n",
    "        \"subplant_id\",\n",
    "        \"unit_id_pudl\",\n",
    "        \"prime_mover_code\",\n",
    "        \"generator_operating_date\",\n",
    "        \"generator_retirement_date\",\n",
    "        \"current_planned_generator_operating_date\",\n",
    "    ]\n",
    "].drop_duplicates(\n",
    "    subset=[\n",
    "        \"plant_id_epa\",\n",
    "        \"emissions_unit_id_epa\",\n",
    "        \"plant_id_eia\",\n",
    "        \"generator_id\",\n",
    "        \"subplant_id\",\n",
    "    ],\n",
    "    keep=\"last\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplant_crosswalk_final.to_csv(f\"test_subplant_{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_19 = pd.read_csv(\"test_subplant_2019.csv\")\n",
    "s_22 = pd.read_csv(\"test_subplant_2022.csv\")\n",
    "\n",
    "test = s_19.merge(\n",
    "    s_22, how=\"outer\", on=[\"plant_id_eia\", \"generator_id\"], suffixes=(\"_19\", \"_22\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: there are occasionally existing plants that never reported to EIA before, but then begin reporting\n",
    "# later. This will throw off the subplant IDs if these were built prior to generators that had already\n",
    "# been reporting (1128, 6), (63580, CAT15)\n",
    "# we may need to sort by earliest reporting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[\n",
    "    (~test[\"subplant_id_19\"].isna())\n",
    "    & (~test[\"subplant_id_22\"].isna())\n",
    "    & (test[\"subplant_id_19\"] != test[\"subplant_id_22\"]),\n",
    "    [\n",
    "        \"plant_id_eia\",\n",
    "        \"generator_id\",\n",
    "        \"unit_id_pudl_19\",\n",
    "        \"unit_id_pudl_22\",\n",
    "        \"subplant_id_19\",\n",
    "        \"subplant_id_22\",\n",
    "    ],\n",
    "].set_index([\"plant_id_eia\", \"generator_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_pm_codes = [\"CA\", \"CT\", \"CS\", \"CC\"]\n",
    "# keep all rows that contain a combined cycle prime mover part\n",
    "cc_subplants = subplant_crosswalk_final.copy()\n",
    "\"\"\"cc_subplants = subplant_crosswalk[\n",
    "    subplant_crosswalk[\"prime_mover_code\"].isin(cc_pm_codes)\n",
    "]\"\"\"\n",
    "# for each subplant, identify a list of all CC prime movers in that subplant\n",
    "cc_subplants = cc_subplants.groupby([\"plant_id_eia\", \"subplant_id\"])[\n",
    "    \"prime_mover_code\"\n",
    "].agg([\"unique\"])\n",
    "cc_subplants[\"unique_cc_pms\"] = [\",\".join(map(str, L)) for L in cc_subplants[\"unique\"]]\n",
    "cc_subplants = cc_subplants.drop(columns=\"unique\")\n",
    "\n",
    "# identify where there are subplants that only contain a single CC part\n",
    "orphaned_cc_parts = cc_subplants[\n",
    "    (cc_subplants[\"unique_cc_pms\"] == \"CA\") | (cc_subplants[\"unique_cc_pms\"] == \"CT\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphaned_cc_parts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_orphaned_cc_part_in_subplant(subplant_crosswalk_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pudl subplant\n",
    "pudl_subplants = load_data.load_pudl_table(\"epacamd_eia_subplant_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_gens[complete_gens[\"plant_id_eia\"] == 375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplant_crosswalk_final[subplant_crosswalk_final[\"plant_id_eia\"] == 1391]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_subplants[pudl_subplants[\"plant_id_eia\"] == 1128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we have to add sort=False to groupby so that it keeps the values in index order\n",
    "# NOTE: ngroup() creates a unique number across the entire dataframe, not per group\n",
    "# pd.factorize() instead creates unique IDs within each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: use_na_sentinel=False creates the same generator ID for all Na values\n",
    "# so this will lead to incorrect subplant groupings. Eg plant 880110 has no generator_id\n",
    "# so all 4 units are assigned a generator_id of 0.\n",
    "# This needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: in some cases, generator_id is missing for plants that are only in CEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The pudl bga table does not contain data for proposed units like Barry A3ST\n",
    "# Even though this has a unit code that links it to other generators\n",
    "# this means that some proposed gens won't be properly linked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Start subplant IDs at 1 rather than 0 index\n",
    "# connect CC parts\n",
    "# check for differences with different years\n",
    "# check for difference between this and the pudl subplants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_grid_emissions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b893a8d8fbb165be288531947168b3b06bdb1508177327a21c265e0400df3100"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
